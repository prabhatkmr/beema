services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: beema-postgres
    environment:
      POSTGRES_DB: beema_kernel
      POSTGRES_USER: beema
      POSTGRES_PASSWORD: beema
    ports:
      - "5433:5432"  # Using 5433 to avoid conflict with host PostgreSQL
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init-databases.sh:/docker-entrypoint-initdb.d/init-databases.sh
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U beema -d beema_kernel"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - beema-network

  # MinIO - S3-Compatible Object Storage
  minio:
    image: minio/minio:latest
    container_name: beema-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password123
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO Console
    volumes:
      - minio_data:/data
    networks:
      - beema-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Keycloak for OAuth2/OIDC (using PostgreSQL)
  keycloak:
    image: quay.io/keycloak/keycloak:23.0
    container_name: beema-keycloak
    command: start-dev
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres:5432/keycloak
      KC_DB_USERNAME: beema
      KC_DB_PASSWORD: beema
      KC_HOSTNAME_STRICT: false
      KC_HTTP_ENABLED: true
      KC_HEALTH_ENABLED: true
    ports:
      - "8180:8080"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/localhost/8080 && echo -e 'GET /health/ready HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' >&3 && timeout 2 cat <&3 | head -1 | grep -q '200'"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - beema-network

  # Metadata Service
  metadata-service:
    build:
      context: ./apps/metadata-service
      dockerfile: Dockerfile
    container_name: beema-metadata
    environment:
      # Database configuration
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: beema_metadata
      DB_USERNAME: beema
      DB_PASSWORD: beema

      # OAuth2 configuration
      OAUTH2_ISSUER_URI: http://keycloak:8080/realms/beema
      OAUTH2_JWK_SET_URI: http://keycloak:8080/realms/beema/protocol/openid-connect/certs

      # Kafka configuration
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_CONTROL_TOPIC: message-hooks-control

      # Spring profiles (uncomment if needed)
      # SPRING_PROFILES_ACTIVE: dev,json-logging
    ports:
      - "8082:8082"
    depends_on:
      postgres:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8082/actuator/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    networks:
      - beema-network

  # Temporal Server (using auto-setup image)
  temporal:
    image: temporalio/auto-setup:1.25.2
    container_name: beema-temporal
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=beema
      - POSTGRES_PWD=beema
      - POSTGRES_SEEDS=postgres
    ports:
      - "7233:7233"  # Temporal gRPC
    healthcheck:
      test: ["CMD", "tctl", "--address", "temporal:7233", "cluster", "health"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - beema-network
    volumes:
      - temporal_data:/etc/temporal

  # Temporal Web UI
  temporal-ui:
    image: temporalio/ui:2.32.0
    container_name: beema-temporal-ui
    depends_on:
      temporal:
        condition: service_healthy
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    ports:
      - "8088:8080"
    networks:
      - beema-network

  # Jaeger - Distributed Tracing Backend
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: beema-jaeger
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - METRICS_STORAGE_TYPE=prometheus
      - PROMETHEUS_SERVER_URL=http://prometheus:9090
    ports:
      - "16686:16686"  # Jaeger UI
      - "4317:4317"    # OTLP gRPC receiver
      - "4318:4318"    # OTLP HTTP receiver
      - "14268:14268"  # Jaeger collector HTTP
      - "14250:14250"  # Jaeger gRPC
    networks:
      - beema-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:16686"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:v3.0.1
    container_name: beema-prometheus
    volumes:
      - ./platform/observability/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    networks:
      - beema-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Grafana - Observability Dashboards
  grafana:
    image: grafana/grafana:11.4.0
    container_name: beema-grafana
    depends_on:
      prometheus:
        condition: service_healthy
      jaeger:
        condition: service_healthy
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3001
      - GF_INSTALL_PLUGINS=grafana-clock-panel
    volumes:
      - ./platform/observability/grafana/provisioning:/etc/grafana/provisioning
      - grafana_data:/var/lib/grafana
    ports:
      - "3001:3000"
    networks:
      - beema-network
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Beema Kernel Service (with Temporal Worker)
  beema-kernel:
    build:
      context: ./beema-kernel
      dockerfile: Dockerfile
    container_name: beema-kernel
    environment:
      # Database configuration
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: beema_kernel
      DB_USERNAME: beema
      DB_PASSWORD: beema

      # Metadata Service URL
      METADATA_SERVICE_URL: http://metadata-service:8082

      # OAuth2 configuration (adjust realm name as needed)
      OAUTH2_ISSUER_URI: http://keycloak:8080/realms/beema
      OAUTH2_JWK_SET_URI: http://keycloak:8080/realms/beema/protocol/openid-connect/certs

      # Temporal configuration
      TEMPORAL_HOST: temporal
      TEMPORAL_PORT: 7233
      TEMPORAL_NAMESPACE: default
      TEMPORAL_WORKER_ENABLED: true
      TEMPORAL_TASK_QUEUE: POLICY_TASK_QUEUE
      TEMPORAL_MAX_CONCURRENT_ACTIVITIES: 10
      TEMPORAL_MAX_CONCURRENT_WORKFLOWS: 10

      # Inngest configuration
      INNGEST_EVENT_KEY: local
      INNGEST_SIGNING_KEY: test-signing-key
      INNGEST_BASE_URL: http://inngest:8288

      # MinIO / S3 storage configuration
      STORAGE_TYPE: s3
      S3_ENDPOINT: http://minio:9000
      S3_REGION: us-east-1
      S3_BUCKET: beema-exports
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password123

      # OpenTelemetry configuration
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4318
      OTEL_SERVICE_NAME: beema-kernel
      OTEL_RESOURCE_ATTRIBUTES: service.name=beema-kernel,deployment.environment=docker
      ENVIRONMENT: docker

      # Spring profiles (uncomment if needed)
      # SPRING_PROFILES_ACTIVE: dev,json-logging
    ports:
      - "8080:8080"
    depends_on:
      postgres:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      metadata-service:
        condition: service_healthy
      temporal:
        condition: service_healthy
      inngest:
        condition: service_healthy
      jaeger:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8080/actuator/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    networks:
      - beema-network

  # ===========================================================================
  # Option 1: Kafka + Zookeeper (Default)
  # ===========================================================================

  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    container_name: beema-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - beema-network
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log

  # Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: beema-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - beema-network
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka Init - Create topics
  kafka-init:
    image: confluentinc/cp-kafka:7.6.0
    container_name: beema-kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      # Create raw-messages topic
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists \
        --topic raw-messages \
        --partitions 3 \
        --replication-factor 1 \
        --config retention.ms=604800000

      # Create processed-messages topic
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists \
        --topic processed-messages \
        --partitions 3 \
        --replication-factor 1 \
        --config retention.ms=604800000

      # Create beema-events topic (transformed messages)
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists \
        --topic beema-events \
        --partitions 6 \
        --replication-factor 1 \
        --config retention.ms=2592000000

      # Create message-hooks-control topic (broadcast stream)
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists \
        --topic message-hooks-control \
        --partitions 1 \
        --replication-factor 1 \
        --config retention.ms=-1 \
        --config cleanup.policy=compact

      # Create beema.events.policy_change topic (policy event stream for datalake)
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists \
        --topic beema.events.policy_change \
        --partitions 6 \
        --replication-factor 1 \
        --config retention.ms=2592000000

      echo 'Topics created successfully'
      "
    networks:
      - beema-network

  # ===========================================================================
  # Option 2: Redpanda (Kafka-Compatible, Zookeeper-Free)
  # Uncomment to use Redpanda instead of Kafka + Zookeeper
  # ===========================================================================
  #
  # redpanda:
  #   image: docker.redpanda.com/redpandadata/redpanda:v24.3.1
  #   container_name: beema-redpanda
  #   command:
  #     - redpanda
  #     - start
  #     - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
  #     - --advertise-kafka-addr internal://redpanda:9092,external://localhost:19092
  #     - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
  #     - --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:18082
  #     - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
  #     - --rpc-addr redpanda:33145
  #     - --advertise-rpc-addr redpanda:33145
  #     - --mode dev-container
  #     - --smp 2
  #     - --memory 2G
  #   ports:
  #     - "19092:19092"  # Kafka API (external)
  #     - "18081:18081"  # Schema Registry (external)
  #     - "18082:18082"  # HTTP Proxy (external)
  #     - "9644:9644"    # Admin API
  #   volumes:
  #     - redpanda_data:/var/lib/redpanda/data
  #   networks:
  #     - beema-network
  #   healthcheck:
  #     test: ["CMD-SHELL", "rpk cluster health"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #
  # redpanda-console:
  #   image: docker.redpanda.com/redpandadata/console:v2.8.0
  #   container_name: beema-redpanda-console
  #   depends_on:
  #     - redpanda
  #   environment:
  #     KAFKA_BROKERS: redpanda:9092
  #     KAFKA_SCHEMAREGISTRY_ENABLED: true
  #     KAFKA_SCHEMAREGISTRY_URLS: http://redpanda:8081
  #   ports:
  #     - "8089:8080"
  #   networks:
  #     - beema-network

  # ===========================================================================
  # Apache Flink Cluster
  # ===========================================================================

  # Flink JobManager (Master)
  flink-jobmanager:
    image: flink:1.18.1
    container_name: beema-flink-jobmanager
    ports:
      - "8081:8081"  # Flink Web UI Dashboard
      - "6123:6123"  # JobManager RPC
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        jobmanager.rpc.port: 6123
        jobmanager.bind-host: 0.0.0.0
        jobmanager.memory.process.size: 1600m
        taskmanager.numberOfTaskSlots: 4
        parallelism.default: 2
        state.backend: rocksdb
        state.checkpoints.dir: s3://beema-checkpoints/checkpoints
        state.savepoints.dir: s3://beema-checkpoints/savepoints
        execution.checkpointing.interval: 60000
        execution.checkpointing.mode: EXACTLY_ONCE
        s3.endpoint: http://minio:9000
        s3.path.style.access: true
        s3.access-key: admin
        s3.secret-key: password123
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password123
    command: >
      bash -c "
        mkdir -p /opt/flink/plugins/s3-fs-hadoop &&
        cp /opt/flink/opt/flink-s3-fs-hadoop-*.jar /opt/flink/plugins/s3-fs-hadoop/ &&
        /docker-entrypoint.sh jobmanager
      "
    volumes:
      - flink_checkpoints:/tmp/flink-checkpoints
      - flink_savepoints:/tmp/flink-savepoints
    depends_on:
      minio:
        condition: service_healthy
    networks:
      - beema-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/overview || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Flink TaskManager (Worker)
  flink-taskmanager:
    image: flink:1.18.1
    depends_on:
      flink-jobmanager:
        condition: service_healthy
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        jobmanager.rpc.port: 6123
        taskmanager.numberOfTaskSlots: 4
        taskmanager.memory.process.size: 2048m
        taskmanager.memory.managed.fraction: 0.4
        parallelism.default: 2
        s3.endpoint: http://minio:9000
        s3.path.style.access: true
        s3.access-key: admin
        s3.secret-key: password123
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password123
    command: >
      bash -c "
        mkdir -p /opt/flink/plugins/s3-fs-hadoop &&
        cp /opt/flink/opt/flink-s3-fs-hadoop-*.jar /opt/flink/plugins/s3-fs-hadoop/ &&
        /docker-entrypoint.sh taskmanager
      "
    networks:
      - beema-network
    volumes:
      - flink_checkpoints:/tmp/flink-checkpoints
      - flink_savepoints:/tmp/flink-savepoints
    scale: 2  # Run 2 TaskManagers for parallel processing

  # Beema Message Processor (Flink Job Submission)
  beema-message-processor:
    build:
      context: ./apps/beema-message-processor
      dockerfile: Dockerfile
    container_name: beema-message-processor-job
    environment:
      # Kafka configuration
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_GROUP_ID: beema-message-processor
      KAFKA_SOURCE_TOPIC: raw-messages
      KAFKA_SINK_TOPIC: beema-events
      KAFKA_CONTROL_TOPIC: message-hooks-control

      # Database configuration
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: beema_kernel
      DB_USERNAME: beema
      DB_PASSWORD: beema

      # Flink configuration
      FLINK_JOBMANAGER_HOST: flink-jobmanager
      FLINK_JOBMANAGER_PORT: 6123
      FLINK_JOB_NAME: beema-message-processor
      FLINK_PARALLELISM: 4
      FLINK_CHECKPOINT_INTERVAL: 60000
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
      flink-jobmanager:
        condition: service_healthy
    networks:
      - beema-network
    command: >
      sh -c "
      echo 'Waiting for Flink JobManager to be ready...';
      sleep 10;
      echo 'Submitting Flink job to JobManager...';
      /opt/flink/bin/flink run
        --jobmanager flink-jobmanager:8081
        --detached
        /opt/flink/usrlib/beema-message-processor.jar
      "

  # Beema Streaming (Flink Job: Kafka -> Parquet -> MinIO Datalake)
  beema-streaming:
    build:
      context: ./apps/beema-streaming
      dockerfile: Dockerfile
    container_name: beema-streaming-job
    environment:
      # Kafka configuration
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_GROUP_ID: beema-policy-streaming
      KAFKA_SOURCE_TOPIC: beema.events.policy_change

      # S3/MinIO configuration
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: admin
      S3_SECRET_KEY: password123
      S3_PATH_STYLE_ACCESS: "true"
      S3_OUTPUT_PATH: s3a://beema-datalake/speed/policy/

      # Flink configuration
      FLINK_JOB_NAME: beema-policy-data-stream
      FLINK_PARALLELISM: 2
      FLINK_CHECKPOINT_INTERVAL: 300000
    depends_on:
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
      minio:
        condition: service_healthy
      flink-jobmanager:
        condition: service_healthy
    networks:
      - beema-network
    command: >
      sh -c "
      echo 'Waiting for Flink JobManager to be ready...';
      sleep 10;
      echo 'Submitting Beema Streaming Flink job...';
      /opt/flink/bin/flink run
        --jobmanager flink-jobmanager:8081
        --detached
        /opt/flink/usrlib/beema-streaming.jar
      "

  # Inngest Dev Server
  inngest:
    image: inngest/inngest:latest
    container_name: beema-inngest
    command: inngest dev
    ports:
      - "8288:8288"  # Inngest Dev Server UI and API
    environment:
      - INNGEST_DEV_SERVER_PORT=8288
      - INNGEST_SIGNING_KEY=test-signing-key
      - INNGEST_LOG_LEVEL=info
    networks:
      - beema-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8288/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - inngest_data:/app/.inngest

  # Beema Studio - Visual Message Blueprint Editor
  studio:
    build:
      context: .
      dockerfile: apps/studio/Dockerfile
    container_name: beema-studio
    environment:
      NEXT_PUBLIC_API_BASE_URL: http://beema-kernel:8080/api/v1
      INNGEST_EVENT_KEY: local
      INNGEST_SIGNING_KEY: test-signing-key
      NEXT_PUBLIC_INNGEST_URL: http://localhost:8288
    ports:
      - "3000:3000"
    depends_on:
      inngest:
        condition: service_healthy
      beema-kernel:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s
    networks:
      - beema-network

volumes:
  postgres_data:
    driver: local
  minio_data:
    driver: local
  temporal_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local
  flink_checkpoints:
    driver: local
  flink_savepoints:
    driver: local
  inngest_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  # redpanda_data:  # Uncomment if using Redpanda
  #   driver: local

networks:
  beema-network:
    driver: bridge
